{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up tokenizer and word dictionary\n",
    "corpus_count = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harryyee/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#import training data\n",
    "#categories meme:0      news:1\n",
    "#format -----> (category number) ||| (title)\n",
    "data = np.genfromtxt('/Users/harryyee/Documents/data_science/mnClean.data', delimiter='|||',dtype=None, usecols=(0,1))\n",
    "\n",
    "#title data x\n",
    "dataX = [x[1] for x in data]\n",
    "\n",
    "#categories data y\n",
    "dataY = [y[0] for y in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up\n",
    "tok = Tokenizer(num_words=corpus_count)\n",
    "tok.fit_on_texts(dataX)\n",
    "mapper = tok.word_index\n",
    "\n",
    "#save word mapping to json file\n",
    "with open('data_map.json','w+') as mapperfile:\n",
    "    json.dump(mapper, mapperfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToNumber(l):\n",
    "    return [mapper[x] for x in kpt.text_to_word_sequence(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedText = []\n",
    "for x in dataX:\n",
    "    eText = textToNumber(x)\n",
    "    encodedText.append(eText)\n",
    "encodedText = np.asarray(encodedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "setX = tok.sequences_to_matrix(encodedText, mode='binary')\n",
    "setY = keras.utils.to_categorical(dataY,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50246 samples, validate on 8868 samples\n",
      "Epoch 1/4\n",
      "50246/50246 [==============================] - 20s 390us/step - loss: 0.0489 - acc: 0.9793 - val_loss: 0.0418 - val_acc: 0.9823\n",
      "Epoch 2/4\n",
      "50246/50246 [==============================] - 19s 378us/step - loss: 0.0319 - acc: 0.9871 - val_loss: 0.0427 - val_acc: 0.9837\n",
      "Epoch 3/4\n",
      "50246/50246 [==============================] - 19s 381us/step - loss: 0.0194 - acc: 0.9922 - val_loss: 0.0486 - val_acc: 0.9826\n",
      "Epoch 4/4\n",
      "50246/50246 [==============================] - 19s 381us/step - loss: 0.0124 - acc: 0.9946 - val_loss: 0.0562 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123dbdf90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model setup\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(corpus_count,), activation='relu'))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(setX,setY,batch_size = 16,epochs=4,verbose =1,validation_split=.15,shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSave = model.to_json()\n",
    "with open ('newsMeme.json', 'w+') as f:\n",
    "    f.write(modelSave)\n",
    "    \n",
    "model.save_weights('newsMeme.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
